{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6703c192",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b720b5c0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Unable to convert function return value to a Python type! The signature was\n\t() -> handle",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3400\\1791906988.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mActivation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSGD\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtyping\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_typing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodule_util\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_module_util\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlazy_loader\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLazyLoader\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_LazyLoader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;31m# Bring in subpackages.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdistribute\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;31m# from tensorflow.python import keras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;31m# pylint: disable=unused-import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mexperimental\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset_ops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAUTOTUNE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset_ops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[1;31m# pylint: disable=unused-import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mservice\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatching\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdense_to_ragged_batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatching\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdense_to_sparse_batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\service\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    417\u001b[0m \"\"\"\n\u001b[0;32m    418\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 419\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_service_ops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdistribute\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    420\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_service_ops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfrom_dataset_id\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    421\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_service_ops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mregister_dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\ops\\data_service_ops.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprotobuf\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdata_service_pb2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtf2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcompression_ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mservice\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_pywrap_server_lib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mservice\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_pywrap_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\ops\\compression_ops.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m# ==============================================================================\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;34m\"\"\"Ops for compressing and uncompressing dataset elements.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstructure\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgen_experimental_dataset_ops\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mged_ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\util\\structure.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mwrapt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcomposite_tensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\util\\nest.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m \"\"\"\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msparse_tensor\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_sparse_tensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_pywrap_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\sparse_tensor.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtf2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcomposite_tensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtypes_pb2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meager\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meager\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mexecute\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mop_callbacks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpywrap_tfe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meager\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensor_shape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdocs\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdoc_controls\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m \u001b[0m_np_bfloat16\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_pywrap_bfloat16\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_bfloat16_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[0m_np_float8_e4m3fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_pywrap_float8\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_float8_e4m3fn_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[0m_np_float8_e5m2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_pywrap_float8\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_float8_e5m2_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Unable to convert function return value to a Python type! The signature was\n\t() -> handle"
     ]
    }
   ],
   "source": [
    "#Import libraries\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    import nltk\n",
    "    from nltk.stem import WordNetLemmatizer\n",
    "    import json\n",
    "    import pickle\n",
    "    import pandas as pd\n",
    "\n",
    "    import numpy as np\n",
    "    from tensorflow.keras.models import Sequential\n",
    "    from tensorflow.keras.layers import Dense, Activation, Dropout\n",
    "    from tensorflow.keras.optimizers import SGD\n",
    "    import random\n",
    "    from keras.models import load_model\n",
    "\n",
    "    #Create an object of WordNetLemmatizer\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    #Import the GL Bot corpus file for preprocessing\n",
    "    words=[]\n",
    "    classes = []\n",
    "    documents = []\n",
    "    ignore_words = ['?', '!']\n",
    "    firstaid_file = open(\"firstaid.json\").read()\n",
    "    intents = json.loads(firstaid_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a06b7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71fc277",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "82a92153",
   "metadata": {},
   "source": [
    "### Data Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927ea472",
   "metadata": {},
   "outputs": [],
   "source": [
    "intents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe4b3a1",
   "metadata": {},
   "source": [
    "### Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "141cbf42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\mavis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\mavis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "for intent in intents['intents']:\n",
    "    for pattern in intent['patterns']:\n",
    "\n",
    "        #Tokenize each word\n",
    "        w = nltk.word_tokenize(pattern)\n",
    "        words.extend(w)\n",
    "        \n",
    "        #Add documents in the corpus\n",
    "        documents.append((w, intent['tag']))\n",
    "\n",
    "        #Add into classes of list\n",
    "        if intent['tag'] not in classes:\n",
    "            classes.append(intent['tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "303b5ac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\mavis\\anaconda3\\lib\\site-packages (3.7)\n",
      "Requirement already satisfied: tqdm in c:\\users\\mavis\\anaconda3\\lib\\site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: joblib in c:\\users\\mavis\\anaconda3\\lib\\site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: click in c:\\users\\mavis\\anaconda3\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\mavis\\anaconda3\\lib\\site-packages (from nltk) (2022.7.9)\n",
      "Requirement already satisfied: colorama in c:\\users\\mavis\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "254c184a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\mavis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f484661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "267 documents\n",
      "43 classes ['Abdominal Pain', 'Abrasions', 'Animal Bite', 'Broken Teeth', 'Broken Toe', 'Bruises', 'CPR', 'Chemical Burn', 'Choking', 'Cold', 'Cough', 'Cuts', 'Diarrhea', 'Drowning', 'Emergency Number', 'Exit', 'Eye Injury', 'Fainting', 'Fever', 'Food Poison', 'Fracture', 'Frost bite', 'Gastrointestinal problems', 'Greetings', 'Head Injury', 'Headache', 'Heat Exhaustion', 'Insect Bite', 'Nasal Congestion', 'Nose Bleed', 'Pulled Muscle', 'Rash', 'Seizure', 'Skin problems', 'Snake bite', 'Sore Throat', 'Splinter', 'Sprains', 'Stings', 'Strains', 'Sun Burn', 'Vertigo', 'Wound']\n",
      "206 unique lemmatized words ['a', 'abdominal', 'abdominalpain', 'abrasion', 'aid', 'allergy', 'am', 'ambulance', 'an', 'animal', 'ankle', 'ant', 'anyone', 'apply', 'are', 'balance', 'bee', 'belong', 'best', 'better', 'bit', 'bite', 'bitten', 'bleed', 'bleeding', 'blocked', 'blood', 'bone', 'bring', 'broke', 'broken', 'bruise', 'bruised', 'buddy', 'burn', 'by', 'call', 'cat', 'catch', 'cause', 'chatbot', 'chemical', 'choke', 'choked', 'choking', 'cold', 'congestion', 'contact', 'cough', 'coughed', 'cpr', 'cream', 'cure', 'cut', 'cya', 'day', 'diagnose', 'diarrhea', 'do', 'doe', 'dog', 'drowned', 'drowning', 'due', 'ear', 'emergency', 'exhausted', 'exhaustion', 'eye', 'faint', 'fainted', 'fainting', 'feel', 'fever', 'first', 'food', 'for', 'forehead', 'fracture', 'from', 'frost', 'frostbite', 'gas', 'gastritis', 'gastrointestinal', 'get', 'give', 'good', 'goodbye', 'got', 'great', 'have', 'head', 'headache', 'heat', 'hello', 'help', 'helped', 'hey', 'hi', 'high', 'hospital', 'hotline', 'how', 'i', 'ice', 'if', 'in', 'injured', 'injury', 'insect', 'is', 'itchy', 'laosai', 'last', 'later', 'learn', 'learner', 'learning', 'leaving', 'like', 'listen', 'long', 'lot', 'me', 'medicine', 'mild', 'monekey', 'monkey', 'muscle', 'my', 'nasal', 'need', 'nose', 'number', 'of', 'off', 'on', 'or', 'overheat', 'pain', 'painful', 'person', 'plant', 'please', 'poison', 'poisoned', 'poisoning', 'problem', 'pulled', 'rash', 'remove', 'rid', 'saved', 'scar', 'see', 'seizure', 'skin', 'snake', 'so', 'someone', 'sore', 'splinter', 'sprain', 'sprained', 'start', 'step', 'sting', 'stomach', 'strain', 'stroke', 'stung', 'sun', 'sunb', 'sunburned', 'surface', 'swallow', 'take', 'talking', 'teeth', 'telephone', 'temperature', 'thank', 'thanks', 'the', 'there', 'throat', 'time', 'to', 'toe', 'ton', 'tooth', 'treat', 'up', 'vertigo', 'vomit', 'water', 'what', 'whats', 'which', 'wood', 'wound', 'wounded', 'ya', 'yo', 'you']\n"
     ]
    }
   ],
   "source": [
    "#Lemmatize, lowercase each word and remove duplicates\n",
    "words = [lemmatizer.lemmatize(w.lower()) for w in words if w not in ignore_words]\n",
    "words = sorted(list(set(words)))\n",
    "\n",
    "#Sort the words by classes\n",
    "classes = sorted(list(set(classes)))\n",
    "\n",
    "#Documents = combination between patterns and intents\n",
    "print (len(documents), \"documents\")\n",
    "\n",
    "#Classes = intents\n",
    "print (len(classes), \"classes\", classes)\n",
    "\n",
    "#Words = all words, vocabulary\n",
    "print (len(words), \"unique lemmatized words\", words)\n",
    "\n",
    "#Creating a pickle file to store the Python objects which we will use while predicting\n",
    "pickle.dump(words,open('words.pkl','wb')) \n",
    "pickle.dump(classes,open('classes.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "270cdbca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data has been created\n"
     ]
    }
   ],
   "source": [
    "#Create the training data\n",
    "training = []\n",
    "\n",
    "#Create an empty array for the output\n",
    "output_empty = [0] * len(classes)\n",
    "\n",
    "#Training set, bag of words for each sentence\n",
    "for doc in documents:\n",
    "    \n",
    "    #Initialize our bag of words\n",
    "    bag = []\n",
    "    \n",
    "    #List of tokenized words for the pattern\n",
    "    pattern_words = doc[0]\n",
    "   \n",
    "    #Lemmatize each word - create base word, in attempt to represent related words\n",
    "    pattern_words = [lemmatizer.lemmatize(word.lower()) for word in pattern_words]\n",
    "    \n",
    "    #Create our bag of words array with 1, if word match found in current pattern\n",
    "    for w in words:\n",
    "        bag.append(1) if w in pattern_words else bag.append(0)\n",
    "    \n",
    "    #Output is a '0' for each tag and '1' for current tag (for each pattern)\n",
    "    output_row = list(output_empty)\n",
    "    output_row[classes.index(doc[1])] = 1\n",
    "    training.append([bag, output_row])\n",
    "\n",
    "#Shuffle features and converting it into numpy arrays\n",
    "random.shuffle(training)\n",
    "training = np.array(training)\n",
    "\n",
    "#Create train and test lists\n",
    "train_x = list(training[:,0])\n",
    "train_y = list(training[:,1])\n",
    "\n",
    "print(\"Training data has been created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09767a6e",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92c3ae56",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Create Neural Network model to predict the responses\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_shape=(len(train_x[0]),), activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(len(train_y[0]), activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37bb8f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile model. Stochastic gradient descent with Nesterov accelerated gradient gives good results for this model\n",
    "#sgd = SGD(learning_rate=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "#model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "#Compile model. Stochastic gradient descent with Nesterov accelerated gradient gives good results for this model\n",
    "sgd = SGD(learning_rate=0.01, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "152d1a03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "27/27 [==============================] - 1s 971us/step - loss: 3.7672 - accuracy: 0.0375\n",
      "Epoch 2/300\n",
      "27/27 [==============================] - 0s 901us/step - loss: 3.7342 - accuracy: 0.0787\n",
      "Epoch 3/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 3.6904 - accuracy: 0.0749\n",
      "Epoch 4/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 3.6455 - accuracy: 0.0899\n",
      "Epoch 5/300\n",
      "27/27 [==============================] - 0s 972us/step - loss: 3.6271 - accuracy: 0.0824\n",
      "Epoch 6/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 3.5630 - accuracy: 0.1049\n",
      "Epoch 7/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 3.5231 - accuracy: 0.0899\n",
      "Epoch 8/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 3.4856 - accuracy: 0.0936\n",
      "Epoch 9/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 3.3953 - accuracy: 0.1273\n",
      "Epoch 10/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 3.3673 - accuracy: 0.1161\n",
      "Epoch 11/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 3.2503 - accuracy: 0.1423\n",
      "Epoch 12/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 3.2117 - accuracy: 0.1648\n",
      "Epoch 13/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 3.1467 - accuracy: 0.2135\n",
      "Epoch 14/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 3.0661 - accuracy: 0.2172\n",
      "Epoch 15/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 2.9159 - accuracy: 0.2509\n",
      "Epoch 16/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 2.8260 - accuracy: 0.2622\n",
      "Epoch 17/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 2.7030 - accuracy: 0.2622\n",
      "Epoch 18/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 2.5801 - accuracy: 0.3146\n",
      "Epoch 19/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 2.4965 - accuracy: 0.3596\n",
      "Epoch 20/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 2.2924 - accuracy: 0.3970\n",
      "Epoch 21/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 2.3097 - accuracy: 0.3745\n",
      "Epoch 22/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 2.1241 - accuracy: 0.4345\n",
      "Epoch 23/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 2.0573 - accuracy: 0.4307\n",
      "Epoch 24/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 2.0038 - accuracy: 0.4007\n",
      "Epoch 25/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 1.9061 - accuracy: 0.5281\n",
      "Epoch 26/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 1.7989 - accuracy: 0.5056\n",
      "Epoch 27/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 1.6241 - accuracy: 0.5880\n",
      "Epoch 28/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 1.5656 - accuracy: 0.5730\n",
      "Epoch 29/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 1.5249 - accuracy: 0.6404\n",
      "Epoch 30/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 1.5226 - accuracy: 0.5955\n",
      "Epoch 31/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 1.3837 - accuracy: 0.6404\n",
      "Epoch 32/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 1.2887 - accuracy: 0.6816\n",
      "Epoch 33/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 1.1788 - accuracy: 0.7004\n",
      "Epoch 34/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 1.1455 - accuracy: 0.6891\n",
      "Epoch 35/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 1.2331 - accuracy: 0.6629\n",
      "Epoch 36/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 1.0853 - accuracy: 0.7116\n",
      "Epoch 37/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 1.0894 - accuracy: 0.6779\n",
      "Epoch 38/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 1.0584 - accuracy: 0.7116\n",
      "Epoch 39/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 1.0445 - accuracy: 0.6891\n",
      "Epoch 40/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.8685 - accuracy: 0.7790\n",
      "Epoch 41/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.8832 - accuracy: 0.7528\n",
      "Epoch 42/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.8641 - accuracy: 0.7453\n",
      "Epoch 43/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.9067 - accuracy: 0.7491\n",
      "Epoch 44/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.8404 - accuracy: 0.7715\n",
      "Epoch 45/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.7387 - accuracy: 0.7978\n",
      "Epoch 46/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.7528 - accuracy: 0.7940\n",
      "Epoch 47/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.7531 - accuracy: 0.7903\n",
      "Epoch 48/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.7284 - accuracy: 0.7790\n",
      "Epoch 49/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.7099 - accuracy: 0.7865\n",
      "Epoch 50/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.6596 - accuracy: 0.8315\n",
      "Epoch 51/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.6140 - accuracy: 0.8352\n",
      "Epoch 52/300\n",
      "27/27 [==============================] - 0s 992us/step - loss: 0.5636 - accuracy: 0.8390\n",
      "Epoch 53/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5885 - accuracy: 0.8502\n",
      "Epoch 54/300\n",
      "27/27 [==============================] - 0s 969us/step - loss: 0.5174 - accuracy: 0.8801\n",
      "Epoch 55/300\n",
      "27/27 [==============================] - 0s 876us/step - loss: 0.5879 - accuracy: 0.8427\n",
      "Epoch 56/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5751 - accuracy: 0.8464\n",
      "Epoch 57/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.4159 - accuracy: 0.9213\n",
      "Epoch 58/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5178 - accuracy: 0.8614\n",
      "Epoch 59/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5017 - accuracy: 0.8801\n",
      "Epoch 60/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5600 - accuracy: 0.8390\n",
      "Epoch 61/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5091 - accuracy: 0.8652\n",
      "Epoch 62/300\n",
      "27/27 [==============================] - 0s 993us/step - loss: 0.5035 - accuracy: 0.8539\n",
      "Epoch 63/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5145 - accuracy: 0.8352\n",
      "Epoch 64/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.4289 - accuracy: 0.8764\n",
      "Epoch 65/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.2972 - accuracy: 0.9363\n",
      "Epoch 66/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.4471 - accuracy: 0.8727\n",
      "Epoch 67/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.3807 - accuracy: 0.8914\n",
      "Epoch 68/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.4766 - accuracy: 0.8764\n",
      "Epoch 69/300\n",
      "27/27 [==============================] - 0s 952us/step - loss: 0.3702 - accuracy: 0.8727\n",
      "Epoch 70/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.4173 - accuracy: 0.8689\n",
      "Epoch 71/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.4046 - accuracy: 0.8876\n",
      "Epoch 72/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.3062 - accuracy: 0.9438\n",
      "Epoch 73/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.4252 - accuracy: 0.8989\n",
      "Epoch 74/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.3309 - accuracy: 0.8989\n",
      "Epoch 75/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.3837 - accuracy: 0.9026\n",
      "Epoch 76/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.3926 - accuracy: 0.8876\n",
      "Epoch 77/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.3545 - accuracy: 0.8727\n",
      "Epoch 78/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.3171 - accuracy: 0.9176\n",
      "Epoch 79/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.3680 - accuracy: 0.8989\n",
      "Epoch 80/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.2895 - accuracy: 0.9363\n",
      "Epoch 81/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.3487 - accuracy: 0.8989\n",
      "Epoch 82/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.3134 - accuracy: 0.9101\n",
      "Epoch 83/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.2894 - accuracy: 0.9176\n",
      "Epoch 84/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.3042 - accuracy: 0.9213\n",
      "Epoch 85/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.2921 - accuracy: 0.9101\n",
      "Epoch 86/300\n",
      "27/27 [==============================] - 0s 981us/step - loss: 0.3279 - accuracy: 0.8914\n",
      "Epoch 87/300\n",
      "27/27 [==============================] - 0s 953us/step - loss: 0.2631 - accuracy: 0.9213\n",
      "Epoch 88/300\n",
      "27/27 [==============================] - 0s 929us/step - loss: 0.3425 - accuracy: 0.8876\n",
      "Epoch 89/300\n",
      "27/27 [==============================] - 0s 961us/step - loss: 0.2988 - accuracy: 0.9363\n",
      "Epoch 90/300\n",
      "27/27 [==============================] - 0s 991us/step - loss: 0.3076 - accuracy: 0.9139\n",
      "Epoch 91/300\n",
      "27/27 [==============================] - 0s 995us/step - loss: 0.2586 - accuracy: 0.9401\n",
      "Epoch 92/300\n",
      "27/27 [==============================] - 0s 956us/step - loss: 0.2480 - accuracy: 0.9288\n",
      "Epoch 93/300\n",
      "27/27 [==============================] - 0s 962us/step - loss: 0.2484 - accuracy: 0.9251\n",
      "Epoch 94/300\n",
      "27/27 [==============================] - 0s 999us/step - loss: 0.2445 - accuracy: 0.9213\n",
      "Epoch 95/300\n",
      "27/27 [==============================] - 0s 977us/step - loss: 0.2994 - accuracy: 0.9026\n",
      "Epoch 96/300\n",
      "27/27 [==============================] - 0s 900us/step - loss: 0.2411 - accuracy: 0.9363\n",
      "Epoch 97/300\n",
      "27/27 [==============================] - 0s 928us/step - loss: 0.2832 - accuracy: 0.9213\n",
      "Epoch 98/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.2885 - accuracy: 0.9064\n",
      "Epoch 99/300\n",
      "27/27 [==============================] - 0s 951us/step - loss: 0.2455 - accuracy: 0.9363\n",
      "Epoch 100/300\n",
      "27/27 [==============================] - 0s 989us/step - loss: 0.2330 - accuracy: 0.9363\n",
      "Epoch 101/300\n",
      "27/27 [==============================] - 0s 954us/step - loss: 0.2534 - accuracy: 0.9401\n",
      "Epoch 102/300\n",
      "27/27 [==============================] - 0s 996us/step - loss: 0.2741 - accuracy: 0.9064\n",
      "Epoch 103/300\n",
      "27/27 [==============================] - 0s 937us/step - loss: 0.2670 - accuracy: 0.9064\n",
      "Epoch 104/300\n",
      "27/27 [==============================] - 0s 913us/step - loss: 0.2548 - accuracy: 0.9326\n",
      "Epoch 105/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.2651 - accuracy: 0.9101\n",
      "Epoch 106/300\n",
      "27/27 [==============================] - 0s 989us/step - loss: 0.2465 - accuracy: 0.9401\n",
      "Epoch 107/300\n",
      "27/27 [==============================] - 0s 957us/step - loss: 0.2720 - accuracy: 0.9139\n",
      "Epoch 108/300\n",
      "27/27 [==============================] - 0s 973us/step - loss: 0.2469 - accuracy: 0.9438\n",
      "Epoch 109/300\n",
      "27/27 [==============================] - 0s 962us/step - loss: 0.2572 - accuracy: 0.9326\n",
      "Epoch 110/300\n",
      "27/27 [==============================] - 0s 989us/step - loss: 0.2429 - accuracy: 0.9176\n",
      "Epoch 111/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.2353 - accuracy: 0.9213\n",
      "Epoch 112/300\n",
      "27/27 [==============================] - 0s 999us/step - loss: 0.2234 - accuracy: 0.9213\n",
      "Epoch 113/300\n",
      "27/27 [==============================] - 0s 983us/step - loss: 0.2095 - accuracy: 0.9326\n",
      "Epoch 114/300\n",
      "27/27 [==============================] - 0s 943us/step - loss: 0.1702 - accuracy: 0.9588\n",
      "Epoch 115/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.1857 - accuracy: 0.9401\n",
      "Epoch 116/300\n",
      "27/27 [==============================] - 0s 989us/step - loss: 0.1823 - accuracy: 0.9588\n",
      "Epoch 117/300\n",
      "27/27 [==============================] - 0s 983us/step - loss: 0.2322 - accuracy: 0.9139\n",
      "Epoch 118/300\n",
      "27/27 [==============================] - 0s 985us/step - loss: 0.2476 - accuracy: 0.9176\n",
      "Epoch 119/300\n",
      "27/27 [==============================] - 0s 948us/step - loss: 0.2384 - accuracy: 0.9288\n",
      "Epoch 120/300\n",
      "27/27 [==============================] - 0s 973us/step - loss: 0.1915 - accuracy: 0.9438\n",
      "Epoch 121/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.2115 - accuracy: 0.9438\n",
      "Epoch 122/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.1977 - accuracy: 0.9476\n",
      "Epoch 123/300\n",
      "27/27 [==============================] - 0s 977us/step - loss: 0.1995 - accuracy: 0.9476\n",
      "Epoch 124/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.2331 - accuracy: 0.9288\n",
      "Epoch 125/300\n",
      "27/27 [==============================] - 0s 995us/step - loss: 0.2241 - accuracy: 0.9326\n",
      "Epoch 126/300\n",
      "27/27 [==============================] - 0s 968us/step - loss: 0.1915 - accuracy: 0.9476\n",
      "Epoch 127/300\n",
      "27/27 [==============================] - 0s 989us/step - loss: 0.1576 - accuracy: 0.9588\n",
      "Epoch 128/300\n",
      "27/27 [==============================] - 0s 967us/step - loss: 0.1815 - accuracy: 0.9476\n",
      "Epoch 129/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.2274 - accuracy: 0.9213\n",
      "Epoch 130/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.2642 - accuracy: 0.9363\n",
      "Epoch 131/300\n",
      "27/27 [==============================] - 0s 941us/step - loss: 0.1878 - accuracy: 0.9438\n",
      "Epoch 132/300\n",
      "27/27 [==============================] - 0s 999us/step - loss: 0.1947 - accuracy: 0.9513\n",
      "Epoch 133/300\n",
      "27/27 [==============================] - 0s 956us/step - loss: 0.1756 - accuracy: 0.9513\n",
      "Epoch 134/300\n",
      "27/27 [==============================] - 0s 991us/step - loss: 0.1927 - accuracy: 0.9438\n",
      "Epoch 135/300\n",
      "27/27 [==============================] - 0s 972us/step - loss: 0.1486 - accuracy: 0.9738\n",
      "Epoch 136/300\n",
      "27/27 [==============================] - 0s 995us/step - loss: 0.2096 - accuracy: 0.9476\n",
      "Epoch 137/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.1545 - accuracy: 0.9625\n",
      "Epoch 138/300\n",
      "27/27 [==============================] - 0s 988us/step - loss: 0.1957 - accuracy: 0.9363\n",
      "Epoch 139/300\n",
      "27/27 [==============================] - 0s 955us/step - loss: 0.1368 - accuracy: 0.9663\n",
      "Epoch 140/300\n",
      "27/27 [==============================] - 0s 981us/step - loss: 0.1873 - accuracy: 0.9438\n",
      "Epoch 141/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.1679 - accuracy: 0.9663\n",
      "Epoch 142/300\n",
      "27/27 [==============================] - 0s 976us/step - loss: 0.1353 - accuracy: 0.9775\n",
      "Epoch 143/300\n",
      "27/27 [==============================] - 0s 972us/step - loss: 0.2005 - accuracy: 0.9251\n",
      "Epoch 144/300\n",
      "27/27 [==============================] - 0s 966us/step - loss: 0.1497 - accuracy: 0.9551\n",
      "Epoch 145/300\n",
      "27/27 [==============================] - 0s 987us/step - loss: 0.0982 - accuracy: 0.9738\n",
      "Epoch 146/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.1565 - accuracy: 0.9663\n",
      "Epoch 147/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.1305 - accuracy: 0.9663\n",
      "Epoch 148/300\n",
      "27/27 [==============================] - 0s 961us/step - loss: 0.1860 - accuracy: 0.9551\n",
      "Epoch 149/300\n",
      "27/27 [==============================] - 0s 958us/step - loss: 0.1753 - accuracy: 0.9513\n",
      "Epoch 150/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.1459 - accuracy: 0.9588\n",
      "Epoch 151/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.1469 - accuracy: 0.9476\n",
      "Epoch 152/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.1288 - accuracy: 0.9663\n",
      "Epoch 153/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.1482 - accuracy: 0.9625\n",
      "Epoch 154/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.1381 - accuracy: 0.9551\n",
      "Epoch 155/300\n",
      "27/27 [==============================] - 0s 995us/step - loss: 0.1467 - accuracy: 0.9663\n",
      "Epoch 156/300\n",
      "27/27 [==============================] - 0s 992us/step - loss: 0.1671 - accuracy: 0.9438\n",
      "Epoch 157/300\n",
      "27/27 [==============================] - 0s 982us/step - loss: 0.1820 - accuracy: 0.9438\n",
      "Epoch 158/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.1246 - accuracy: 0.9738\n",
      "Epoch 159/300\n",
      "27/27 [==============================] - 0s 992us/step - loss: 0.1105 - accuracy: 0.9738\n",
      "Epoch 160/300\n",
      "27/27 [==============================] - 0s 996us/step - loss: 0.1274 - accuracy: 0.9625\n",
      "Epoch 161/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.1103 - accuracy: 0.9700\n",
      "Epoch 162/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 0s 1ms/step - loss: 0.1328 - accuracy: 0.9700\n",
      "Epoch 163/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0961 - accuracy: 0.9813\n",
      "Epoch 164/300\n",
      "27/27 [==============================] - 0s 989us/step - loss: 0.1875 - accuracy: 0.9438\n",
      "Epoch 165/300\n",
      "27/27 [==============================] - 0s 942us/step - loss: 0.1367 - accuracy: 0.9513\n",
      "Epoch 166/300\n",
      "27/27 [==============================] - 0s 963us/step - loss: 0.1441 - accuracy: 0.9700\n",
      "Epoch 167/300\n",
      "27/27 [==============================] - 0s 980us/step - loss: 0.1314 - accuracy: 0.9513\n",
      "Epoch 168/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.1901 - accuracy: 0.9438\n",
      "Epoch 169/300\n",
      "27/27 [==============================] - 0s 993us/step - loss: 0.1052 - accuracy: 0.9663\n",
      "Epoch 170/300\n",
      "27/27 [==============================] - 0s 947us/step - loss: 0.1677 - accuracy: 0.9438\n",
      "Epoch 171/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.1585 - accuracy: 0.9551\n",
      "Epoch 172/300\n",
      "27/27 [==============================] - 0s 994us/step - loss: 0.2060 - accuracy: 0.9326\n",
      "Epoch 173/300\n",
      "27/27 [==============================] - 0s 979us/step - loss: 0.1645 - accuracy: 0.9625\n",
      "Epoch 174/300\n",
      "27/27 [==============================] - 0s 934us/step - loss: 0.1379 - accuracy: 0.9551\n",
      "Epoch 175/300\n",
      "27/27 [==============================] - 0s 983us/step - loss: 0.1410 - accuracy: 0.9438\n",
      "Epoch 176/300\n",
      "27/27 [==============================] - 0s 965us/step - loss: 0.1137 - accuracy: 0.9588\n",
      "Epoch 177/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.1632 - accuracy: 0.9625\n",
      "Epoch 178/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0962 - accuracy: 0.9775\n",
      "Epoch 179/300\n",
      "27/27 [==============================] - 0s 950us/step - loss: 0.1760 - accuracy: 0.9513\n",
      "Epoch 180/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0937 - accuracy: 0.9775\n",
      "Epoch 181/300\n",
      "27/27 [==============================] - 0s 938us/step - loss: 0.1474 - accuracy: 0.9625\n",
      "Epoch 182/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.1556 - accuracy: 0.9588\n",
      "Epoch 183/300\n",
      "27/27 [==============================] - 0s 995us/step - loss: 0.1257 - accuracy: 0.9551\n",
      "Epoch 184/300\n",
      "27/27 [==============================] - 0s 997us/step - loss: 0.1346 - accuracy: 0.9700\n",
      "Epoch 185/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.1264 - accuracy: 0.9663\n",
      "Epoch 186/300\n",
      "27/27 [==============================] - 0s 971us/step - loss: 0.1136 - accuracy: 0.9700\n",
      "Epoch 187/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.1303 - accuracy: 0.9663\n",
      "Epoch 188/300\n",
      "27/27 [==============================] - 0s 992us/step - loss: 0.1000 - accuracy: 0.9700\n",
      "Epoch 189/300\n",
      "27/27 [==============================] - 0s 970us/step - loss: 0.1300 - accuracy: 0.9738\n",
      "Epoch 190/300\n",
      "27/27 [==============================] - 0s 971us/step - loss: 0.0869 - accuracy: 0.9850\n",
      "Epoch 191/300\n",
      "27/27 [==============================] - 0s 969us/step - loss: 0.1379 - accuracy: 0.9551\n",
      "Epoch 192/300\n",
      "27/27 [==============================] - 0s 948us/step - loss: 0.1722 - accuracy: 0.9288\n",
      "Epoch 193/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.1367 - accuracy: 0.9738\n",
      "Epoch 194/300\n",
      "27/27 [==============================] - 0s 989us/step - loss: 0.1279 - accuracy: 0.9551\n",
      "Epoch 195/300\n",
      "27/27 [==============================] - 0s 971us/step - loss: 0.1364 - accuracy: 0.9588\n",
      "Epoch 196/300\n",
      "27/27 [==============================] - 0s 972us/step - loss: 0.1687 - accuracy: 0.9513\n",
      "Epoch 197/300\n",
      "27/27 [==============================] - 0s 965us/step - loss: 0.1614 - accuracy: 0.9551\n",
      "Epoch 198/300\n",
      "27/27 [==============================] - 0s 931us/step - loss: 0.1291 - accuracy: 0.9663\n",
      "Epoch 199/300\n",
      "27/27 [==============================] - 0s 967us/step - loss: 0.1194 - accuracy: 0.9513\n",
      "Epoch 200/300\n",
      "27/27 [==============================] - 0s 992us/step - loss: 0.1226 - accuracy: 0.9700\n",
      "Epoch 201/300\n",
      "27/27 [==============================] - 0s 994us/step - loss: 0.1068 - accuracy: 0.9738\n",
      "Epoch 202/300\n",
      "27/27 [==============================] - 0s 992us/step - loss: 0.1402 - accuracy: 0.9476\n",
      "Epoch 203/300\n",
      "27/27 [==============================] - 0s 991us/step - loss: 0.0990 - accuracy: 0.9775\n",
      "Epoch 204/300\n",
      "27/27 [==============================] - 0s 958us/step - loss: 0.1460 - accuracy: 0.9625\n",
      "Epoch 205/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.1335 - accuracy: 0.9588\n",
      "Epoch 206/300\n",
      "27/27 [==============================] - 0s 988us/step - loss: 0.1381 - accuracy: 0.9551\n",
      "Epoch 207/300\n",
      "27/27 [==============================] - 0s 977us/step - loss: 0.1171 - accuracy: 0.9625\n",
      "Epoch 208/300\n",
      "27/27 [==============================] - 0s 979us/step - loss: 0.1652 - accuracy: 0.9513\n",
      "Epoch 209/300\n",
      "27/27 [==============================] - 0s 942us/step - loss: 0.1031 - accuracy: 0.9663\n",
      "Epoch 210/300\n",
      "27/27 [==============================] - 0s 983us/step - loss: 0.1098 - accuracy: 0.9625\n",
      "Epoch 211/300\n",
      "27/27 [==============================] - 0s 991us/step - loss: 0.1509 - accuracy: 0.9476\n",
      "Epoch 212/300\n",
      "27/27 [==============================] - 0s 995us/step - loss: 0.0943 - accuracy: 0.9850\n",
      "Epoch 213/300\n",
      "27/27 [==============================] - 0s 993us/step - loss: 0.1554 - accuracy: 0.9513\n",
      "Epoch 214/300\n",
      "27/27 [==============================] - 0s 973us/step - loss: 0.1034 - accuracy: 0.9700\n",
      "Epoch 215/300\n",
      "27/27 [==============================] - 0s 959us/step - loss: 0.1087 - accuracy: 0.9850\n",
      "Epoch 216/300\n",
      "27/27 [==============================] - 0s 987us/step - loss: 0.0920 - accuracy: 0.9738\n",
      "Epoch 217/300\n",
      "27/27 [==============================] - 0s 995us/step - loss: 0.1399 - accuracy: 0.9551\n",
      "Epoch 218/300\n",
      "27/27 [==============================] - 0s 972us/step - loss: 0.1411 - accuracy: 0.9588\n",
      "Epoch 219/300\n",
      "27/27 [==============================] - 0s 980us/step - loss: 0.0941 - accuracy: 0.9700\n",
      "Epoch 220/300\n",
      "27/27 [==============================] - 0s 945us/step - loss: 0.1639 - accuracy: 0.9476\n",
      "Epoch 221/300\n",
      "27/27 [==============================] - 0s 960us/step - loss: 0.1900 - accuracy: 0.9401\n",
      "Epoch 222/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.1193 - accuracy: 0.9625\n",
      "Epoch 223/300\n",
      "27/27 [==============================] - 0s 995us/step - loss: 0.1103 - accuracy: 0.9663\n",
      "Epoch 224/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0927 - accuracy: 0.9700\n",
      "Epoch 225/300\n",
      "27/27 [==============================] - 0s 994us/step - loss: 0.1591 - accuracy: 0.9476\n",
      "Epoch 226/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.1048 - accuracy: 0.9738\n",
      "Epoch 227/300\n",
      "27/27 [==============================] - 0s 988us/step - loss: 0.0901 - accuracy: 0.9700\n",
      "Epoch 228/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0801 - accuracy: 0.9813\n",
      "Epoch 229/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.1195 - accuracy: 0.9625\n",
      "Epoch 230/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.1143 - accuracy: 0.9700\n",
      "Epoch 231/300\n",
      "27/27 [==============================] - 0s 981us/step - loss: 0.1500 - accuracy: 0.9551\n",
      "Epoch 232/300\n",
      "27/27 [==============================] - 0s 969us/step - loss: 0.0763 - accuracy: 0.9813\n",
      "Epoch 233/300\n",
      "27/27 [==============================] - 0s 996us/step - loss: 0.1123 - accuracy: 0.9663\n",
      "Epoch 234/300\n",
      "27/27 [==============================] - 0s 967us/step - loss: 0.1046 - accuracy: 0.9738\n",
      "Epoch 235/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0947 - accuracy: 0.9738\n",
      "Epoch 236/300\n",
      "27/27 [==============================] - 0s 995us/step - loss: 0.0940 - accuracy: 0.9738\n",
      "Epoch 237/300\n",
      "27/27 [==============================] - 0s 991us/step - loss: 0.0895 - accuracy: 0.9813\n",
      "Epoch 238/300\n",
      "27/27 [==============================] - 0s 981us/step - loss: 0.0767 - accuracy: 0.9738\n",
      "Epoch 239/300\n",
      "27/27 [==============================] - 0s 975us/step - loss: 0.0965 - accuracy: 0.9738\n",
      "Epoch 240/300\n",
      "27/27 [==============================] - 0s 894us/step - loss: 0.0949 - accuracy: 0.9700\n",
      "Epoch 241/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0818 - accuracy: 0.9738\n",
      "Epoch 242/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 0s 995us/step - loss: 0.1109 - accuracy: 0.9700\n",
      "Epoch 243/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0875 - accuracy: 0.9700\n",
      "Epoch 244/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.1469 - accuracy: 0.9551\n",
      "Epoch 245/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0946 - accuracy: 0.9775\n",
      "Epoch 246/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.1801 - accuracy: 0.9513\n",
      "Epoch 247/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0849 - accuracy: 0.9738\n",
      "Epoch 248/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.1003 - accuracy: 0.9663\n",
      "Epoch 249/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.1080 - accuracy: 0.9625\n",
      "Epoch 250/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0956 - accuracy: 0.9700\n",
      "Epoch 251/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.1202 - accuracy: 0.9700\n",
      "Epoch 252/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0953 - accuracy: 0.9625\n",
      "Epoch 253/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0701 - accuracy: 0.9850\n",
      "Epoch 254/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.1205 - accuracy: 0.9588\n",
      "Epoch 255/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.1349 - accuracy: 0.9663\n",
      "Epoch 256/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.1012 - accuracy: 0.9625\n",
      "Epoch 257/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.1074 - accuracy: 0.9625\n",
      "Epoch 258/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0987 - accuracy: 0.9738\n",
      "Epoch 259/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.1340 - accuracy: 0.9551\n",
      "Epoch 260/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.1099 - accuracy: 0.9663\n",
      "Epoch 261/300\n",
      "27/27 [==============================] - 0s 996us/step - loss: 0.0792 - accuracy: 0.9775\n",
      "Epoch 262/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0951 - accuracy: 0.9775\n",
      "Epoch 263/300\n",
      "27/27 [==============================] - 0s 993us/step - loss: 0.0844 - accuracy: 0.9738\n",
      "Epoch 264/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0760 - accuracy: 0.9813\n",
      "Epoch 265/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0721 - accuracy: 0.9813\n",
      "Epoch 266/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.1700 - accuracy: 0.9401\n",
      "Epoch 267/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.1094 - accuracy: 0.9551\n",
      "Epoch 268/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0802 - accuracy: 0.9813\n",
      "Epoch 269/300\n",
      "27/27 [==============================] - 0s 995us/step - loss: 0.1194 - accuracy: 0.9663\n",
      "Epoch 270/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.1119 - accuracy: 0.9663\n",
      "Epoch 271/300\n",
      "27/27 [==============================] - 0s 960us/step - loss: 0.0629 - accuracy: 0.9850\n",
      "Epoch 272/300\n",
      "27/27 [==============================] - 0s 945us/step - loss: 0.1029 - accuracy: 0.9775\n",
      "Epoch 273/300\n",
      "27/27 [==============================] - 0s 966us/step - loss: 0.1197 - accuracy: 0.9588\n",
      "Epoch 274/300\n",
      "27/27 [==============================] - 0s 967us/step - loss: 0.0962 - accuracy: 0.9775\n",
      "Epoch 275/300\n",
      "27/27 [==============================] - 0s 980us/step - loss: 0.0875 - accuracy: 0.9700\n",
      "Epoch 276/300\n",
      "27/27 [==============================] - 0s 960us/step - loss: 0.0802 - accuracy: 0.9813\n",
      "Epoch 277/300\n",
      "27/27 [==============================] - 0s 975us/step - loss: 0.1328 - accuracy: 0.9551\n",
      "Epoch 278/300\n",
      "27/27 [==============================] - 0s 984us/step - loss: 0.0853 - accuracy: 0.9738\n",
      "Epoch 279/300\n",
      "27/27 [==============================] - 0s 920us/step - loss: 0.1110 - accuracy: 0.9700\n",
      "Epoch 280/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.1002 - accuracy: 0.9625\n",
      "Epoch 281/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.1018 - accuracy: 0.9700\n",
      "Epoch 282/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.1030 - accuracy: 0.9700\n",
      "Epoch 283/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.1091 - accuracy: 0.9700\n",
      "Epoch 284/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0686 - accuracy: 0.9850\n",
      "Epoch 285/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.1193 - accuracy: 0.9513\n",
      "Epoch 286/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0959 - accuracy: 0.9700\n",
      "Epoch 287/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.1170 - accuracy: 0.9588\n",
      "Epoch 288/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.1373 - accuracy: 0.9663\n",
      "Epoch 289/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0752 - accuracy: 0.9813\n",
      "Epoch 290/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0888 - accuracy: 0.9775\n",
      "Epoch 291/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0805 - accuracy: 0.9775\n",
      "Epoch 292/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.1084 - accuracy: 0.9700\n",
      "Epoch 293/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0633 - accuracy: 0.9850\n",
      "Epoch 294/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.1214 - accuracy: 0.9700\n",
      "Epoch 295/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0952 - accuracy: 0.9813\n",
      "Epoch 296/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0679 - accuracy: 0.9775\n",
      "Epoch 297/300\n",
      "27/27 [==============================] - 0s 932us/step - loss: 0.1225 - accuracy: 0.9513\n",
      "Epoch 298/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.1230 - accuracy: 0.9588\n",
      "Epoch 299/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.1024 - accuracy: 0.9625\n",
      "Epoch 300/300\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0717 - accuracy: 0.9738\n",
      "\n",
      "\n",
      "**************************************************\n",
      "\n",
      "Model Created Successfully!\n"
     ]
    }
   ],
   "source": [
    "#Fitting and saving the model \n",
    "hist = model.fit(np.array(train_x), np.array(train_y), epochs=300, batch_size=10, verbose=1)\n",
    "model.save('chatbot.h5', hist) #We will pickle this model to use in the future\n",
    "print(\"\\n\")\n",
    "print(\"*\"*50)\n",
    "print(\"\\nModel Created Successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66af6177",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the saved model file\n",
    "model = load_model('chatbot.h5')\n",
    "#intents = json.loads(open(\"firstaid.json\").read())\n",
    "df = pd.read_csv(\"course.csv\")\n",
    "intents = df.to_dict(orient='records')\n",
    "words = pickle.load(open('words.pkl','rb'))\n",
    "classes = pickle.load(open('classes.pkl','rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032342a7",
   "metadata": {},
   "source": [
    "### Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f349e653",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_up_sentence(sentence):\n",
    "\n",
    "    #Tokenize the pattern > split words into array\n",
    "    sentence_words = nltk.word_tokenize(sentence)\n",
    "    \n",
    "    #Stem each word > create short form for word\n",
    "    sentence_words = [lemmatizer.lemmatize(word.lower()) for word in sentence_words]\n",
    "    return sentence_words\n",
    "\n",
    "\n",
    "#Return bag of words array: 0 or 1 for each word in the bag that exists in the sentence\n",
    "def bow(sentence, words, show_details=True):\n",
    "\n",
    "    #Tokenize the pattern\n",
    "    sentence_words = clean_up_sentence(sentence)\n",
    "\n",
    "    #Bag of words - matrix of N words, vocabulary matrix\n",
    "    bag = [0]*len(words) \n",
    "    for s in sentence_words:\n",
    "        for i,w in enumerate(words):\n",
    "            if w == s: \n",
    "               \n",
    "                # Assign 1 if current word is in the vocabulary position\n",
    "                bag[i] = 1\n",
    "                if show_details:\n",
    "                    print (\"found in bag: %s\" % w)\n",
    "    return(np.array(bag))\n",
    "\n",
    "def predict_class(sentence, model):\n",
    "   \n",
    "    #Filter out predictions below a threshold\n",
    "    p = bow(sentence, words,show_details=False)\n",
    "    res = model.predict(np.array([p]))[0]\n",
    "    error = 0.25\n",
    "    results = [[i,r] for i,r in enumerate(res) if r>error]\n",
    "    \n",
    "    #Sort by strength of probability\n",
    "    results.sort(key=lambda x: x[1], reverse=True)\n",
    "    return_list = []\n",
    "    \n",
    "    for r in results:\n",
    "        return_list.append({\"intent\": classes[r[0]], \"probability\": str(r[1])})\n",
    "    return return_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22730061",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to get the response from the model\n",
    "\n",
    "def getResponse(ints, intents_json):\n",
    "    tag = ints[0]['intent']\n",
    "    list_of_intents = intents_json['intents']\n",
    "    for i in list_of_intents:\n",
    "        if(i['tag']== tag):\n",
    "            result = random.choice(i['responses'])\n",
    "            break\n",
    "    return result\n",
    "\n",
    "#Function to predict the class and get the response\n",
    "\n",
    "def chatbot_response(text):\n",
    "    ints = predict_class(text, model)\n",
    "    res = getResponse(ints, intents)\n",
    "    return res\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f38af56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fucntion to rate the service before end conversation\n",
    "\n",
    "def rateService():\n",
    "    print(\"-\"*50)\n",
    "    print(\"\\n\"+ \"Thank you for using our AI chatbot. It would be great if you could rate TARUMT chatbot.\" + \"\\n\")\n",
    "    print(\"1 star  - Very unsatisfied\")\n",
    "    print(\"2 stars - Unsatisfied\")\n",
    "    print(\"3 stars - Neutral\")\n",
    "    print(\"4 stars - Satisdfied\")\n",
    "    print(\"5 stars - Very satisfied\")\n",
    "    \n",
    "    rate = int(input(\"Your rating (1-5) > \"))\n",
    "    while rate <= 0 or rate > 5:\n",
    "        print(\"Invalid! Please enter 1 to 5 only.\")\n",
    "        rate = int(input(\"Your rating (1-5) > \"))\n",
    "    if rate == 1 or rate == 2:\n",
    "        print(\"Sorry for the bad experience :( Let's hear us your feedback, it is valuable to us.\")\n",
    "        feedback = str(input(\"Feedback: \"))\n",
    "        print(\"Thank you for your feedback. We will use your feedback for future improvement.\")\n",
    "    else:\n",
    "        print(\"We really appreciate you taking the time to share your rating with us, thank you! :)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf483b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to start the chat bot which will continue until the user type 'end' or 'bye'\n",
    "\n",
    "def startChat():\n",
    "    print(\"TARUMT Bot: Hello! I am TARUMT, your personal AI course offer assistant.\")\n",
    "    name = str(input(\"TARUMT Bot: What is your name ? > \"))\n",
    "    print(\"TARUMT Bot: Nice to meet you, \" + (name) + \"!\")\n",
    "    print(\"-\"*50)\n",
    "    while True:\n",
    "        inp = str(input((name)+\": \"))\n",
    "        if inp.lower()==\"end\" or inp.lower() ==\"bye\":\n",
    "            print(\"TARUMT Bot: Bye \" + (name) + \"!\")\n",
    "            rateService()\n",
    "            break\n",
    "        if inp.lower()== '' or inp.lower()== '*': #If user empty input\n",
    "            print('Please enter again!')\n",
    "            print(\"-\"*50)\n",
    "        else:\n",
    "            print(f\"TARUMT Bot: {chatbot_response(inp)}\"+'\\n')\n",
    "            print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7afcf53e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TARUMT Bot: Hello! I am TARUMT, your personal AI course offer assistant.\n",
      "TARUMT Bot: What is your name ? > hi\n",
      "TARUMT Bot: Nice to meet you, hi!\n",
      "--------------------------------------------------\n",
      "hi: bruise\n",
      "1/1 [==============================] - 0s 15ms/step\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7692\\2080161020.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Start the chat bot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mstartChat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7692\\3420072317.py\u001b[0m in \u001b[0;36mstartChat\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"-\"\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"TARUMT Bot: {chatbot_response(inp)}\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"-\"\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7692\\3691734675.py\u001b[0m in \u001b[0;36mchatbot_response\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mchatbot_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mints\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetResponse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mints\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mintents\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7692\\3691734675.py\u001b[0m in \u001b[0;36mgetResponse\u001b[1;34m(ints, intents_json)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mgetResponse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mints\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mintents_json\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mtag\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mints\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'intent'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mlist_of_intents\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mintents_json\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'intents'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlist_of_intents\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'tag'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m \u001b[0mtag\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "#Start the chat bot\n",
    "startChat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec71e59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
